# 12/31/2020
Been thinking about how exactly to implement PageRank.

A preliminary test showed that the Ruby Matrix class struggles on smallish machines with a square matrix with a few thousand rows.

So: do I break the problem into smaller matrices, use a different Matrix (custom?) class, get larger machines, or avoid an in-memory matrix all together?

I'm thinking I want to break the problem down into smaller matrices.  Ideally, the implementation should be able to adapt to whatever size machine it's on - taking advantage of the larger machine if it can etc.

## Distributed PageRank
### Basic Idea
We find a "starting" page, and fetch all backlinks recursively to some specified depth.  Keep a count of the total number of pages fetched, and keep below a specified threshold. This is our input page set, which we use to create a matrix and perform the algorithm.

Meanwhile, we can find a different starting page - of a certain 'distance' from the other starting page, and perform the same computation.  We can do this in parallel, taking the average of any page ranks calculated for a page in both.

The trick will be finding a way to deterministically run the algorithm on _all_ pages.  I'm sure this basic approach has been done many times before, and I'm sure there are many solutions to this problem.  I think I'll work on my own for a bit before doing more research.

### Implementation
First off: a RankService.  The RankService does the entire computation, updates the database, and traverses the whole graph to make sure all pages have been ranked.

The service will have a few data structures it works with - to start they may be Classes, but it may make sense to use something more performant in the future.

#### Database
- `Page`
  - `rank`
  - `ranked_at`
  - `rank_iterations`

#### Data Structures
- `RankService::Page`
  - `id`
  - `position`
  - `back_links`
  - `start_rank`
  - `finish_rank`
- `RankService::Matrix`
  - `pages`
  - `matrix`
  - `ev`
  - `iterations`

#### Methods
- `rank(max_size)`
  - Starts from Page least recently ranked, or with the lowest `rank_iteration`
- `rank_from_start_page(page, max_size)`
  - Starts from given page


#### Commands
- `CollectPages`
- `GeneratePageMatrix`

## Later that day...
aaaaaand I forgot about importing back into the db.  Unfortunately, I think the best way to do this is to upsert everything.  Which means I need to know everything about the Page I'm going to upsert, since everything gets overwritten.

Soooo, what about all the data on the page?  I'm keeping a lot on there right now - may make sense to put it in a different table?  Otherwise, I'll be carrying around all that data in memory, and I may want to lock the page from having other changes...things get messy.

The bad solution is calling update for everything page...but it is the easiest to do now.  I'm not sure I can stomach even doing it for now.

